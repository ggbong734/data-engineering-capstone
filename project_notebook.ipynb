{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The primary objective of this project is to create a set of fact and dimensions tables and the supporting ETL pipeline to facilitate queries regarding visitors into the United States. The first step is to prepare staging tables in Redshift followed by setting up a set of fact and dimension tables based on the Star schema. Finally, an Airflow DAG is constructed to periodically run the process and check the data quality. \n",
    "\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the mData\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1)\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "\n",
    "The I94_SAS_Labels_Descriptions.SAS provided in the data folder contains several dictionaries which are converted manually into the following .csv files:\n",
    "* visa_type.csv - list of one-digit i94 visa type and their types\n",
    "* i94mode.csv - list of one-digit i94 modes and their respective transportation mode\n",
    "* i94port.csv - list of airport three-character codes, their names, and state/country\n",
    "* i94cit.csv - list of three-digit country codes and their respective names\n",
    "* state_code.csv - list of two-character state codes and their respective names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "fname = 'data/immigration_data_sample.csv'\n",
    "df = pd.read_csv(fname, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2590789</th>\n",
       "      <td>5242730.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>HAM</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20575.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160428</td>\n",
       "      <td>HML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.475131e+10</td>\n",
       "      <td>00560</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846327</th>\n",
       "      <td>1777652.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20565.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160410</td>\n",
       "      <td>WRW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>10092016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>9.319662e+10</td>\n",
       "      <td>00430</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920712</th>\n",
       "      <td>3874218.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>20565.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>07192016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.653427e+10</td>\n",
       "      <td>00454</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451881</th>\n",
       "      <td>930868.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20549.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DC</td>\n",
       "      <td>20552.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160405</td>\n",
       "      <td>GDL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>10042016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UA</td>\n",
       "      <td>9.282073e+10</td>\n",
       "      <td>01567</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517187</th>\n",
       "      <td>5081809.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>07252016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DL</td>\n",
       "      <td>5.932276e+10</td>\n",
       "      <td>00158</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117909</th>\n",
       "      <td>4288772.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>LVG</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>07212016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VS</td>\n",
       "      <td>5.914065e+10</td>\n",
       "      <td>00043</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463022</th>\n",
       "      <td>2947585.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>PSP</td>\n",
       "      <td>20560.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160416</td>\n",
       "      <td>JDD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>10152016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SV</td>\n",
       "      <td>9.371186e+10</td>\n",
       "      <td>00041</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414569</th>\n",
       "      <td>2883298.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20560.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>07142016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AF</td>\n",
       "      <td>5.627747e+10</td>\n",
       "      <td>00090</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094181</th>\n",
       "      <td>2264857.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20556.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WI</td>\n",
       "      <td>20559.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160412</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>10112016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EV</td>\n",
       "      <td>9.334035e+10</td>\n",
       "      <td>05510</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271807</th>\n",
       "      <td>4654865.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20578.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160424</td>\n",
       "      <td>BNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>10232016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LA</td>\n",
       "      <td>9.440386e+10</td>\n",
       "      <td>02514</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "2590789  5242730.0  2016.0  4.0     135.0   509.0   HAM     20572.0  1.0       \n",
       "846327   1777652.0  2016.0  4.0     107.0   107.0   CHI     20554.0  1.0       \n",
       "1920712  3874218.0  2016.0  4.0     148.0   112.0   SFR     20565.0  1.0       \n",
       "451881   930868.0   2016.0  4.0     582.0   582.0   WAS     20549.0  1.0       \n",
       "2517187  5081809.0  2016.0  4.0     254.0   276.0   BOS     20571.0  1.0       \n",
       "2117909  4288772.0  2016.0  4.0     135.0   135.0   LVG     20567.0  1.0       \n",
       "1463022  2947585.0  2016.0  4.0     261.0   261.0   PSP     20560.0  1.0       \n",
       "1414569  2883298.0  2016.0  4.0     111.0   111.0   MIA     20560.0  1.0       \n",
       "1094181  2264857.0  2016.0  4.0     582.0   582.0   ATL     20556.0  1.0       \n",
       "2271807  4654865.0  2016.0  4.0     687.0   687.0   MIA     20568.0  1.0       \n",
       "\n",
       "        i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup  \\\n",
       "2590789  MA      20575.0  47.0    2.0      1.0    20160428  HML      NaN    \n",
       "846327   IL      20565.0  51.0    1.0      1.0    20160410  WRW      NaN    \n",
       "1920712  CA      20582.0  49.0    2.0      1.0    20160421  NaN      NaN    \n",
       "451881   DC      20552.0  42.0    2.0      1.0    20160405  GDL      NaN    \n",
       "2517187  MI      20582.0  51.0    2.0      1.0    20160427  NaN      NaN    \n",
       "2117909  NV      20572.0  32.0    2.0      1.0    20160423  NaN      NaN    \n",
       "1463022  HI      20567.0  35.0    1.0      1.0    20160416  JDD      NaN    \n",
       "1414569  FL      20566.0  39.0    2.0      1.0    20160416  NaN      NaN    \n",
       "1094181  WI      20559.0  35.0    1.0      1.0    20160412  MTR      NaN    \n",
       "2271807  FL      20578.0  44.0    2.0      1.0    20160424  BNS      NaN    \n",
       "\n",
       "        entdepa entdepd  entdepu matflag  biryear   dtaddto gender  insnum  \\\n",
       "2590789  G       O      NaN       M       1969.0   10272016  F     NaN       \n",
       "846327   G       O      NaN       M       1965.0   10092016  F     NaN       \n",
       "1920712  O       O      NaN       M       1967.0   07192016  NaN   NaN       \n",
       "451881   G       O      NaN       M       1974.0   10042016  M     NaN       \n",
       "2517187  G       O      NaN       M       1965.0   07252016  F     NaN       \n",
       "2117909  G       O      NaN       M       1984.0   07212016  M     NaN       \n",
       "1463022  G       O      NaN       M       1981.0   10152016  M     NaN       \n",
       "1414569  G       O      NaN       M       1977.0   07142016  M     NaN       \n",
       "1094181  G       O      NaN       M       1981.0   10112016  M     NaN       \n",
       "2271807  G       O      NaN       M       1972.0   10232016  F     NaN       \n",
       "\n",
       "        airline        admnum  fltno visatype  \n",
       "2590789  DL      9.475131e+10  00560  B2       \n",
       "846327   LH      9.319662e+10  00430  B1       \n",
       "1920712  LH      5.653427e+10  00454  WT       \n",
       "451881   UA      9.282073e+10  01567  B2       \n",
       "2517187  DL      5.932276e+10  00158  WT       \n",
       "2117909  VS      5.914065e+10  00043  WT       \n",
       "1463022  SV      9.371186e+10  00041  B1       \n",
       "1414569  AF      5.627747e+10  00090  WT       \n",
       "1094181  EV      9.334035e+10  05510  B1       \n",
       "2271807  LA      9.440386e+10  02514  B2       "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 2027561 to 2271807\n",
      "Data columns (total 28 columns):\n",
      "cicid       1000 non-null float64\n",
      "i94yr       1000 non-null float64\n",
      "i94mon      1000 non-null float64\n",
      "i94cit      1000 non-null float64\n",
      "i94res      1000 non-null float64\n",
      "i94port     1000 non-null object\n",
      "arrdate     1000 non-null float64\n",
      "i94mode     1000 non-null float64\n",
      "i94addr     941 non-null object\n",
      "depdate     951 non-null float64\n",
      "i94bir      1000 non-null float64\n",
      "i94visa     1000 non-null float64\n",
      "count       1000 non-null float64\n",
      "dtadfile    1000 non-null int64\n",
      "visapost    382 non-null object\n",
      "occup       4 non-null object\n",
      "entdepa     1000 non-null object\n",
      "entdepd     954 non-null object\n",
      "entdepu     0 non-null float64\n",
      "matflag     954 non-null object\n",
      "biryear     1000 non-null float64\n",
      "dtaddto     1000 non-null object\n",
      "gender      859 non-null object\n",
      "insnum      35 non-null float64\n",
      "airline     967 non-null object\n",
      "admnum      1000 non-null float64\n",
      "fltno       992 non-null object\n",
      "visatype    1000 non-null object\n",
      "dtypes: float64(15), int64(1), object(12)\n",
      "memory usage: 226.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\t\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0  4.0     245.0   438.0   LOS     20574.0  1.0       \n",
       "1  5748518.0  2016.0  4.0     245.0   438.0   LOS     20574.0  1.0       \n",
       "2  5748519.0  2016.0  4.0     245.0   438.0   LOS     20574.0  1.0       \n",
       "3  5748520.0  2016.0  4.0     245.0   438.0   LOS     20574.0  1.0       \n",
       "4  5748521.0  2016.0  4.0     245.0   438.0   LOS     20574.0  1.0       \n",
       "\n",
       "  i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa  \\\n",
       "0  CA      20582.0  40.0    1.0      1.0    20160430  SYD      None  G        \n",
       "1  NV      20591.0  32.0    1.0      1.0    20160430  SYD      None  G        \n",
       "2  WA      20582.0  29.0    1.0      1.0    20160430  SYD      None  G        \n",
       "3  WA      20588.0  29.0    1.0      1.0    20160430  SYD      None  G        \n",
       "4  WA      20588.0  28.0    1.0      1.0    20160430  SYD      None  G        \n",
       "\n",
       "  entdepd entdepu matflag  biryear   dtaddto gender insnum airline  \\\n",
       "0  O       None    M       1976.0   10292016  F      None   QF       \n",
       "1  O       None    M       1984.0   10292016  F      None   VA       \n",
       "2  O       None    M       1987.0   10292016  M      None   DL       \n",
       "3  O       None    M       1987.0   10292016  F      None   DL       \n",
       "4  O       None    M       1988.0   10292016  M      None   DL       \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  9.495387e+10  00011  B1       \n",
       "1  9.495562e+10  00007  B1       \n",
       "2  9.495641e+10  00040  B1       \n",
       "3  9.495645e+10  00040  B1       \n",
       "4  9.495639e+10  00040  B1       "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_spark.show(2)\n",
    "df_spark.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data contains codes for airports all over the world\n",
    "df_airport = pd.read_csv('data/airport-codes_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55070</th>\n",
       "      <td>ZYYK</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Yingkou Lanqi Airport</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Yingkou</td>\n",
       "      <td>ZYYK</td>\n",
       "      <td>YKH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.3586, 40.542524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55071</th>\n",
       "      <td>ZYYY</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Shenyang Dongta Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Shenyang</td>\n",
       "      <td>ZYYY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.49600219726562, 41.784400939941406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55072</th>\n",
       "      <td>ZZ-0001</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Sealand Helipad</td>\n",
       "      <td>40.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB-ENG</td>\n",
       "      <td>Sealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4825, 51.894444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55073</th>\n",
       "      <td>ZZ-0002</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Glorioso Islands Airstrip</td>\n",
       "      <td>11.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>TF</td>\n",
       "      <td>TF-U-A</td>\n",
       "      <td>Grande Glorieuse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.296388888900005, -11.584277777799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55074</th>\n",
       "      <td>ZZZZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Satsuma IÅjima Airport</td>\n",
       "      <td>338.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>JP</td>\n",
       "      <td>JP-46</td>\n",
       "      <td>Mishima-Mura</td>\n",
       "      <td>RJX7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.270556, 30.784722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ident            type                       name  elevation_ft  \\\n",
       "55070  ZYYK     medium_airport  Yingkou Lanqi Airport      0.0            \n",
       "55071  ZYYY     medium_airport  Shenyang Dongta Airport   NaN             \n",
       "55072  ZZ-0001  heliport        Sealand Helipad            40.0           \n",
       "55073  ZZ-0002  small_airport   Glorioso Islands Airstrip  11.0           \n",
       "55074  ZZZZ     small_airport   Satsuma IÅjima Airport    338.0          \n",
       "\n",
       "      continent iso_country iso_region      municipality gps_code iata_code  \\\n",
       "55070  AS        CN          CN-21      Yingkou           ZYYK     YKH        \n",
       "55071  AS        CN          CN-21      Shenyang          ZYYY     NaN        \n",
       "55072  EU        GB          GB-ENG     Sealand           NaN      NaN        \n",
       "55073  AF        TF          TF-U-A     Grande Glorieuse  NaN      NaN        \n",
       "55074  AS        JP          JP-46      Mishima-Mura      RJX7     NaN        \n",
       "\n",
       "      local_code                              coordinates  \n",
       "55070  NaN        122.3586, 40.542524                      \n",
       "55071  NaN        123.49600219726562, 41.784400939941406   \n",
       "55072  NaN        1.4825, 51.894444                        \n",
       "55073  NaN        47.296388888900005, -11.584277777799999  \n",
       "55074  NaN        130.270556, 30.784722                    "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      "ident           55075 non-null object\n",
      "type            55075 non-null object\n",
      "name            55075 non-null object\n",
      "elevation_ft    48069 non-null float64\n",
      "continent       27356 non-null object\n",
      "iso_country     54828 non-null object\n",
      "iso_region      55075 non-null object\n",
      "municipality    49399 non-null object\n",
      "gps_code        41030 non-null object\n",
      "iata_code       9189 non-null object\n",
      "local_code      28686 non-null object\n",
      "coordinates     55075 non-null object\n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_airport.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_cities= pd.read_csv('data/us-cities-demographics.csv', delimiter =';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring     Maryland       33.8        40601.0           \n",
       "1  Quincy            Massachusetts  41.0        44129.0           \n",
       "2  Hoover            Alabama        38.5        38040.0           \n",
       "3  Rancho Cucamonga  California     34.5        88127.0           \n",
       "4  Newark            New Jersey     34.6        138040.0          \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0  41862.0            82463             1562.0              30908.0        \n",
       "1  49500.0            93629             4147.0              32935.0        \n",
       "2  46799.0            84839             4819.0              8229.0         \n",
       "3  87105.0            175232            5821.0              33878.0        \n",
       "4  143873.0           281913            5829.0              86253.0        \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0  2.60                    MD         Hispanic or Latino         25924  \n",
       "1  2.39                    MA         White                      58723  \n",
       "2  2.58                    AL         Asian                      4759   \n",
       "3  3.18                    CA         Black or African-American  24437  \n",
       "4  2.73                    NJ         White                      76402  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cities.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no land arrivals)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>324</td>\n",
       "      <td>ANGOLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>529</td>\n",
       "      <td>ANGUILLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>518</td>\n",
       "      <td>ANTIGUA-BARBUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>687</td>\n",
       "      <td>ARGENTINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>151</td>\n",
       "      <td>ARMENIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>532</td>\n",
       "      <td>ARUBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>438</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>103</td>\n",
       "      <td>AUSTRIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>152</td>\n",
       "      <td>AZERBAIJAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>512</td>\n",
       "      <td>BAHAMAS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country_code                                               country_name\n",
       "0   582           MEXICO Air Sea, and Not Reported (I-94, no land arrivals)\n",
       "1   236           AFGHANISTAN                                              \n",
       "2   101           ALBANIA                                                  \n",
       "3   316           ALGERIA                                                  \n",
       "4   102           ANDORRA                                                  \n",
       "5   324           ANGOLA                                                   \n",
       "6   529           ANGUILLA                                                 \n",
       "7   518           ANTIGUA-BARBUDA                                          \n",
       "8   687           ARGENTINA                                                \n",
       "9   151           ARMENIA                                                  \n",
       "10  532           ARUBA                                                    \n",
       "11  438           AUSTRALIA                                                \n",
       "12  103           AUSTRIA                                                  \n",
       "13  152           AZERBAIJAN                                               \n",
       "14  512           BAHAMAS                                                  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_country_code = pd.read_csv('data/country_code.csv')\n",
    "df_country_code.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport_code</th>\n",
       "      <th>airport_name</th>\n",
       "      <th>airport_state_or_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airport_code              airport_name airport_state_or_country\n",
       "0  ALC          ALCAN                     AK                     \n",
       "1  ANC          ANCHORAGE                 AK                     \n",
       "2  BAR          BAKER AAF - BAKER ISLAND  AK                     \n",
       "3  DAC          DALTONS CACHE             AK                     \n",
       "4  PIZ          DEW STATION PT LAY DEW    AK                     "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_code = pd.read_csv('data/i94port.csv')\n",
    "df_airport_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94_mode</th>\n",
       "      <th>transportation_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not reported</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i94_mode transportation_mode\n",
       "0  1         Air               \n",
       "1  2         Sea               \n",
       "2  3         Land              \n",
       "3  9         Not reported      "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans_mode = pd.read_csv('data/i94mode.csv')\n",
    "df_trans_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code  state_name\n",
       "0  AL         ALABAMA   \n",
       "1  AK         ALASKA    \n",
       "2  AZ         ARIZONA   \n",
       "3  AR         ARKANSAS  \n",
       "4  CA         CALIFORNIA"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_state_code = pd.read_csv('data/state_code.csv')\n",
    "df_state_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94_visa</th>\n",
       "      <th>visa_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i94_visa visa_type\n",
       "0  1         Business\n",
       "1  2         Pleasure\n",
       "2  3         Student "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visa = pd.read_csv('data/visa_type.csv')\n",
    "df_visa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "There are several columns with missing values in the immigration dataset. In particular, these columns have more than 5% of the rows missing and are listed in increasing percentage of missing values:\n",
    "* depdate (5% missing)\n",
    "* entdpd (5% missing)\n",
    "* i94addr (6% missing)\n",
    "* gender (15% missing)\n",
    "* visapost (60% missing)\n",
    "* insnum (96% missing)\n",
    "* occup (99% missing)\n",
    "* entdepu (100% missing)\n",
    "\n",
    "The airport dataset has the following columns with missing values:\n",
    "* iso_country (0.5% missing)\n",
    "* municipality (10% missing)\n",
    "* elevation_ft (13% missing)\n",
    "* gps_code (26% missing)\n",
    "* local_code (48% missing)\n",
    "* continent (50% missing)\n",
    "* iata_code (83% missing)\n",
    "\n",
    "The columns with higher than 50% of its data missing are not used in creating the final fact and dimension tables. Imputation techniques such as filling in the average or most common value can only be useful when missing data is less than 15-20%.\n",
    "\n",
    "The US cities demographics data contains very few null values in the following columns (Male Population, Female Population, Number of Veterans, Foreign-born, Average Household Size). As a result, this dataset does not need cleaning.\n",
    "\n",
    "#### Cleaning Steps\n",
    "The `i94port.csv` airport names and airport state/country columns have a lot of extra characters which had to be deleted. City names were sometimes characterized as country names which had to be corrected. Also leading and trailing spaces had to be trimmed. The `visa_type.csv`, `country_code.csv`, `state_code.csv` files required the quotation marks and equals signs removed to create the appropriate tables.  \n",
    "\n",
    "The column `dtaddto` (date added to file) in the immigration dataset had null values as 'D/S'. To accommodate this, when creating the staging_immigration table in Redshift, the column is assigned a VARCHAR data type.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Rolling up cities data into states\n",
    "\n",
    "The `cities` dataset contains information on individual cities but since the immigration dataset only reports the state (not city) of arrival, the cities data is rolled up into states. The median age and household size columns are aggregated using the `mean` function while the population descriptions are rolled up using `sum`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Roll up city data into states and convert some columns into fractions of total population\n",
    "\n",
    "df_states = df_cities.groupby(\"State Code\").agg({\"Median Age\": \"mean\",\n",
    "                                     \"Male Population\": \"sum\",\n",
    "                                     \"Female Population\": \"sum\",\n",
    "                                     \"Total Population\": \"sum\",\n",
    "                                     \"Number of Veterans\": \"sum\",\n",
    "                                     \"Foreign-born\": \"sum\",\n",
    "                                     \"Average Household Size\": \"mean\",\n",
    "                                     \"Count\": \"count\"})\n",
    "\n",
    "# Convert summed values into fraction of total population\n",
    "df_states[\"Male Population\"] = df_states[\"Male Population\"]/df_states[\"Total Population\"]\n",
    "df_states[\"Female Population\"] = df_states[\"Female Population\"]/df_states[\"Total Population\"]\n",
    "df_states[\"Number of Veterans\"] = df_states[\"Number of Veterans\"]/df_states[\"Total Population\"]\n",
    "df_states[\"Foreign-born\"] = df_states[\"Foreign-born\"]/df_states[\"Total Population\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Join df_states with df_state_code\n",
    "df_joined_states = df_state_code.join(df_states, how='left', on='state_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a new csv file with states data\n",
    "df_joined_states.to_csv('data/us_states.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55 entries, 0 to 54\n",
      "Data columns (total 10 columns):\n",
      "state_code                55 non-null object\n",
      "state_name                55 non-null object\n",
      "Median Age                49 non-null float64\n",
      "Male Population           49 non-null float64\n",
      "Female Population         49 non-null float64\n",
      "Total Population          49 non-null float64\n",
      "Number of Veterans        49 non-null float64\n",
      "Foreign-born              49 non-null float64\n",
      "Average Household Size    48 non-null float64\n",
      "Count                     49 non-null float64\n",
      "dtypes: float64(8), object(2)\n",
      "memory usage: 4.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_joined_states.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "To accommodate queries on immigration arrival data, the following facts and dimension tables are created following the Star schema model. The central fact table contains principal information on I-94 form and means of arrival into the United States. The dimensions table provide more detailed information on states, airports, countries, time, and admissions.  \n",
    "\n",
    "![Facts and dimension tables](images/fact_dimension_tables.png)\n",
    "\n",
    "Using the schema above, the following queries can be easily performed:\n",
    "* Airports with the most visitors\n",
    "* Age distribution of visitors into the United States\n",
    "* States with the most number of business visitors per population each year\n",
    "* States with the most number of residents born in a foreign country \n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "To pipeline the data into the chosen model, the first step is to stage the necessary data into staging tables in Redshift:\n",
    "\n",
    "![Staging tables](images/staging_tables.png)\n",
    "\n",
    "Then the data is extracted from these preliminary tables into the final fact and dimensions tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "The following SQL commands are used to create staging tables as well as the final fact and dimension tables in Redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "## SQL Queries to build tables in Redshift#########\n",
    "\n",
    "create_tables= (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS public.staging_immigration (\n",
    "     cicid FLOAT,\n",
    "     i94yr FLOAT,\n",
    "     i94mon FLOAT,\n",
    "     i94cit FLOAT,\n",
    "     i94res FLOAT,\n",
    "     i94port VARCHAR,\n",
    "     arrdate FLOAT,\n",
    "     i94mode FLOAT,\n",
    "     i94addr VARCHAR,\n",
    "     depdate FLOAT,\n",
    "     i94bir FLOAT,\n",
    "     i94visa FLOAT,\n",
    "     count FLOAT,\n",
    "     dtadfile VARCHAR,\n",
    "     visapost VARCHAR,\n",
    "     occup VARCHAR,\n",
    "     entdepa VARCHAR,\n",
    "     entdepd VARCHAR,\n",
    "     entdepu VARCHAR,\n",
    "     matflag VARCHAR,\n",
    "     biryear FLOAT,\n",
    "     dtaddto VARCHAR,\n",
    "     gender VARCHAR,\n",
    "     insnum VARCHAR,\n",
    "     airline VARCHAR,\n",
    "     admnum FLOAT,\n",
    "     fltno VARCHAR,\n",
    "     visatype VARCHAR\n",
    ");\n",
    "     \n",
    "CREATE TABLE IF NOT EXISTS public.states (\n",
    "     state_code VARCHAR,\n",
    "     state_name VARCHAR,\n",
    "     median_age FLOAT,\n",
    "     male_population FLOAT,\n",
    "     female_population FLOAT,\n",
    "     total_population INTEGER,\n",
    "     number_of_veterans FLOAT,\n",
    "     foreign_born FLOAT,\n",
    "     household_size FLOAT,\n",
    "     city_count INTEGER,\n",
    "     CONSTRAINT states_pkey PRIMARY KEY (state_code)\n",
    ");\n",
    "     \n",
    "CREATE TABLE IF NOT EXISTS public.airport_code (\n",
    "     airport_code VARCHAR,\n",
    "     airport_name VARCHAR,\n",
    "     airport_state VARCHAR,\n",
    "     CONSTRAINT airport_pkey PRIMARY KEY (airport_code)\n",
    ");    \n",
    "     \n",
    "CREATE TABLE IF NOT EXISTS public.countries (\n",
    "     country_code VARCHAR,\n",
    "     country_name VARCHAR,\n",
    "     CONSTRAINT countries_pkey PRIMARY KEY (country_code)\n",
    "); \n",
    "\n",
    "CREATE TABLE IF NOT EXISTS public.staging_trans_mode (\n",
    "     i94_mode INTEGER,\n",
    "     transportation_mode VARCHAR,\n",
    "     CONSTRAINT trans_mode_pkey PRIMARY KEY (i94_mode)\n",
    "); \n",
    "     \n",
    "CREATE TABLE IF NOT EXISTS public.staging_visa_code (\n",
    "     i94_visa INTEGER,\n",
    "     visa_type VARCHAR,\n",
    "     CONSTRAINT visa_pkey PRIMARY KEY (i94_visa)\n",
    "); \n",
    "     \n",
    "CREATE TABLE IF NOT EXISTS public.arrivals (\n",
    "     cicid INTEGER,\n",
    "     state_code INTEGER,\n",
    "     country_code INTEGER,\n",
    "     airport_code VARCHAR,\n",
    "     arrdate INTEGER,\n",
    "     arrival_code VARCHAR,\n",
    "     arrival_mode VARCHAR,\n",
    "     state VARCHAR,\n",
    "     airline VARCHAR,\n",
    "     admnum BIGINT,\n",
    "     fltno VARCHAR\n",
    ");\n",
    "     \n",
    "CREATE TABLE IF NOT EXISTS public.admissions (\n",
    "     admnum BIGINT,\n",
    "     gender VARCHAR,\n",
    "     age VARCHAR,\n",
    "     biryear TIMESTAMP,\n",
    "     visa_code INTEGER,\n",
    "     visa_type VARCHAR,\n",
    "     CONSTRAINT admissions_pkey PRIMARY KEY (admnum)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS public.time (\n",
    "    arrdate TIMESTAMP,\n",
    "    month int4,\n",
    "    year int4,\n",
    "    week int4,\n",
    "    day int4,\n",
    "    weekday int4,\n",
    "    CONSTRAINT time_pkey PRIMARY KEY (arrdate)\n",
    ");\n",
    "\"\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Once staging and final tables are created in Redshift, all the data is then copied to the staging tables using the following SQL commands. The US immigration data comes in Parquet format while the airport and US states data are in CSV format thus different commands are used for each data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "## SQL Queries to copy csv tables into Redshift#####\n",
    "\n",
    "copy_sql = \"\"\"\n",
    "COPY {}\n",
    "FROM '{}'\n",
    "ACCESS_KEY_ID '{}'\n",
    "SECRET_ACCESS_KEY '{}'\n",
    "IGNOREHEADER 1\n",
    "CSV;\n",
    "\"\"\"\n",
    "\n",
    "########################################################\n",
    "## SQL Queries to copy parquet tables into Redshift#####\n",
    "\n",
    "copy_parquet_sql = \"\"\"\n",
    "COPY {}\n",
    "FROM '{}'\n",
    "IAM_ROLE '{}'\n",
    "FORMAT AS PARQUET;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Then, data is transferred from the staging tables into the fact and dimension tables. The following SQL commands can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "## SQL Queries to insert tables into Redshift#####\n",
    "        \n",
    "arrivals_table_insert = (\"\"\"\n",
    "SELECT CAST(im.cicid AS INT),\n",
    "       CAST(im.i94cit AS INT) AS state_code,\n",
    "       CAST(im.i94res AS INT) AS country_code,\n",
    "       im.i94port AS airport_code,\n",
    "       CAST(arrdate AS INT),\n",
    "       CAST(im.i94mode AS INT) AS arrival_code,\n",
    "       tm.transportation_mode AS arrival_mode,\n",
    "       im.i94addr AS state,\n",
    "       im.airline,\n",
    "       CAST(im.admnum AS BIGINT),\n",
    "       im.fltno\n",
    "    FROM staging_immigration AS im\n",
    "    LEFT JOIN staging_trans_mode AS tm\n",
    "    ON CAST(im.i94mode AS INT) = tm.i94_mode\n",
    "\"\"\")\n",
    "\n",
    "admissions_table_insert = (\"\"\"\n",
    "SELECT CAST(im.admnum AS BIGINT),\n",
    "       im.gender,\n",
    "       CAST(im.i94bir AS INT),\n",
    "       to_timestamp(CAST(im.biryear AS INT), 'YYYY') as birth_year,\n",
    "       CAST(im.i94visa AS INT),\n",
    "       vs.visa_type\n",
    "    FROM staging_immigration AS im\n",
    "    LEFT JOIN staging_visa_code AS vs\n",
    "    ON CAST(im.i94visa AS INT) = vs.visa_type\n",
    "\"\"\")\n",
    "\n",
    "time_table_insert = (\"\"\"\n",
    "SELECT dates.arrtime AS arrdate,\n",
    "       extract(year from dates.arrtime),\n",
    "       extract(month from dates.arrtime),\n",
    "       extract(week from dates.arrtime), \n",
    "       extract(day from dates.arrtime),\n",
    "       extract(dayofweek from dates.arrtime) AS weekday\n",
    "    FROM (SELECT DATEADD(day, CAST(arrdate AS INT), '1900-01-01') AS arrtime\n",
    "        FROM staging_immigration) dates\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The overall ETL process is then built into a pipeline in Airflow with a daily update schedule. Data quality checks are added at the end of the pipeline to ensure no missing values for the primary keys.\n",
    "![Airflow graph view DAG](images/dag_image.png)\n",
    "\n",
    "5 custom operators are created in Airflow to . Airflow Connections are used to store two credentials: the first credential is a set of AWS access key ID and secret access key for retrieving the raw data on S3; the second credential is a set of database name, username, password, endpoint, and port information to connect to the Redshift database.\n",
    "\n",
    "There is a `aws.cfg` file in the \"dags\" folder which contains the Amazon Resource Name (ARN) of the user's AWS Identity and Access Management (IAM) role which would allow access to the Redshift database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Data quality checks to run:\n",
    " * Integrity check on primary keys of fact and dimensional tables\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data quality checks to run in SQL\n",
    "data_quality_checks =[\n",
    " {'check_sql': \"SELECT COUNT(*) FROM arrivals WHERE cic_id IS NULL\", 'expected_result':0},   \n",
    " {'check_sql': \"SELECT COUNT(*) FROM admissions WHERE admnum IS NULL\", 'expected_result':0},\n",
    " {'check_sql': \"SELECT COUNT(*) FROM time WHERE arrdate IS NULL\", 'expected_result':0},\n",
    " {'check_sql': \"SELECT COUNT(*) FROM states WHERE state_code IS NULL\", 'expected_result':0},\n",
    " {'check_sql': \"SELECT COUNT(*) FROM states WHERE state_code IS NULL\", 'expected_result':0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Upon completion of the steps in the pipeline, the following tree view can be seen on the AirFlow UI:\n",
    "![Airflow Success DAG Tree View](images/success_dag.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Data dictionary for the tables:\n",
    "\n",
    "#### arrival table:\n",
    "* cicid: US immigration identification number\n",
    "* state_code: 2-character state code\n",
    "* country_code: 3-digit country code\n",
    "* airport_code: 3-character airport code\n",
    "* arrdate: arrival date (raw: number of days since 1/1/1900 SAS type number)\n",
    "* arrival_code: 1-digit arrival mode\n",
    "* arrival_mode: mode of transportation to arrive into the US (air, sea, or land)\n",
    "* state: 2-character state code\n",
    "* airline: airline used to enter the US\n",
    "* admnum: admission number\n",
    "* fltno: flight number and airlines used\n",
    "\n",
    "#### states table:\n",
    "* state_code: 2-character state code \n",
    "* state_name: state name\n",
    "* median_age: median age of people in the state\n",
    "* male_population: fraction of male population in the state\n",
    "* female_population: fraction of female population in the state\n",
    "* total_population: number of population based on cities in the database\n",
    "* number_veterans: fraction of veterans in the population\n",
    "* foreign_born: fraction of people that are born in a foreign country\n",
    "* household_size: average number of people in a household\n",
    "* city_count: number of cities accounted for in the state\n",
    "\n",
    "#### admissions table:\n",
    "* adm_num: admission number\n",
    "* gender: gender of person arriving in the US\n",
    "* age: age of person arriving\n",
    "* biryear: year of birth of person arriving\n",
    "* visa_code: 1 digit code visa type\n",
    "* visa_type: type of visa (e.g. business, student, pleasure)\n",
    "\n",
    "#### time table:\n",
    "* arrdate: arrival date\n",
    "* year: year of arrival\n",
    "* month: month of arrival\n",
    "* week: week of the year of arrival (e.g. 1-52)\n",
    "* day: day of the year of arrival (e.g. 1-365)\n",
    "* weekday: weekday of arrival (e.g. 1-7)\n",
    "\n",
    "#### airports table:\n",
    "* airport_code: 3-character airport code\n",
    "* airport_name: name of airport\n",
    "* airport_state: state that airport is located in\n",
    "\n",
    "#### countries table:\n",
    "* country_code: 3-digit country code\n",
    "* country_name: name of country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Justification for technology stack\n",
    "* AWS S3 is chosen as the storage platform due to its low cost, high availability, and compatibility with AWS Redshift.\n",
    "\n",
    "* Redshift is selected to host the relational table since it allows for easy start-up process, security, and fast scaling. Further, it has an SQL interface and works very well with data stored in AWS S3 (high performance parallel loading).\n",
    "\n",
    "* Airflow is selected as the primary technology to schedule and track the workflow in the ETL pipeline. Airflow provides a simple user interface and the ability to monitor tasks and send alerts in case any of the process fails. In addition, Airflow is easily extendable through the use of custom operators, hooks, and sensors. \n",
    "\n",
    "#### Additional thoughts\n",
    "\n",
    "* The database can be updated on a daily basis as there are over 80 million visitors to the United States every year which is roughly 7 million visitors per month or 230,000 visitors per week. This schedule allows for frequent updates while not requiring too much resources (compute and duration) on each update.  \n",
    "\n",
    "\n",
    "* In the scenario that the data was increased by 100x:\n",
    "    * One alternative would be to host the data on multiple clusters of machine and use Spark SQL to leverage the power of distributed computing in order to speed up the data ingestion and processing steps. \n",
    "    \n",
    "    \n",
    "* In the scenario that the data populates a dashboard that must be updated on a daily basis by 7am every day:\n",
    "    * I would continue to use AirFlow to update the data but will add a service level agreement to ensure that the data processing is completed before the daily deadline. An alert email can be set up to indicate failure along the process to allow early detection.\n",
    "\n",
    "\n",
    "* In the scenario that the database needed to be accessed by 100+ people:\n",
    "    * I would chooose a database system that is compatible with Spark as Spark has powerful built-in tools to handle concurrent operations by scheduling work in a sequential manner while still enabling parallelism."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
